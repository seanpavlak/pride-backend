{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from phe import paillier\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_Alice = np.array([[5.1, 3.5, 1.4, 0.2],\n",
    "              [4.9, 3.0, 1.4, 0.2],\n",
    "              [4.7, 3.2, 1.3, 0.2],\n",
    "              [4.6, 3.1, 1.5, 0.2],\n",
    "              [5.0, 3.6, 1.4, 0.2],\n",
    "              [6.4, 3.1, 5.5, 1.8],\n",
    "              [6.0, 3.0, 4.8, 1.8],\n",
    "              [6.9, 3.1, 5.4, 2.1],\n",
    "              [6.7, 3.1, 5.6, 2.4],\n",
    "              [6.9, 3.1, 5.1, 2.3],\n",
    "              [5.8, 2.7, 5.1, 1.9]]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_Alice_res = np.array([[1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_Bob = [    [ 5.4,3.9,1.7,0.4 ],\n",
    "                [ 4.6,3.4,1.4,0.3 ],\n",
    "                [ 5.0,3.4,1.5,0.2 ],\n",
    "                [ 4.4,2.9,1.4,0.2 ],\n",
    "                [ 6.9,3.1,5.4,2.1 ],\n",
    "                [ 6.7,3.1,5.6,2.4 ],\n",
    "                [ 6.9,3.1,5.1,2.3 ],\n",
    "                [ 5.4,3.7,1.5,0.2 ],\n",
    "                [ 4.8,3.4,1.6,0.2 ],\n",
    "                [ 4.8,3.0,1.4,0.1 ],\n",
    "                [ 4.3,3.0,1.1,0.1 ],\n",
    "                [ 6.4,2.7,5.3,1.9 ],\n",
    "                [ 6.8,3.0,5.5,2.1 ],\n",
    "                [ 5.7,2.5,5.0,2.0 ],\n",
    "                [ 5.8,2.8,5.1,2.4 ],\n",
    "                [ 5.8,4.0,1.2,0.2 ],\n",
    "                [ 5.7,4.4,1.5,0.4 ],\n",
    "                [ 5.1,3.8,1.5,0.3 ],\n",
    "                [ 5.4,3.4,1.7,0.2 ],\n",
    "                [ 5.1,3.7,1.5,0.4 ],\n",
    "                [ 7.7,3.8,6.7,2.2 ],\n",
    "                [ 7.7,2.6,6.9,2.3 ],\n",
    "                [ 6.0,2.2,5.0,1.5 ],\n",
    "                [ 6.9,3.2,5.7,2.3 ],\n",
    "                [ 5.6,2.8,4.9,2.0 ],\n",
    "                [ 4.6,3.6,1.0,0.2 ],\n",
    "                [ 5.2,4.1,1.5,0.1 ],\n",
    "                [ 5.5,4.2,1.4,0.2 ],\n",
    "                [ 4.9,3.1,1.5,0.1 ],\n",
    "                [ 5.0,3.2,1.2,0.2 ],\n",
    "                [ 5.5,3.5,1.3,0.2 ],\n",
    "                [ 4.5,2.3,1.3,0.3 ],\n",
    "                [ 4.8,3.0,1.4,0.3 ],\n",
    "                [ 5.1,3.8,1.6,0.2 ],\n",
    "                [ 4.6,3.2,1.4,0.2 ],\n",
    "                [ 5.3,3.7,1.5,0.2 ],\n",
    "                [ 7.1,3.0,5.9,2.0 ],\n",
    "                [ 6.3,2.9,5.6,1.8 ],\n",
    "                [ 6.5,3.0,5.8,2.2 ],\n",
    "                [ 7.6,3.0,6.6,2.1 ],\n",
    "                [ 4.9,2.5,4.5,1.7 ],\n",
    "                [ 6.4,3.2,5.3,2.3 ],\n",
    "                [ 6.5,3.0,5.5,1.8 ],\n",
    "                [ 7.7,2.8,6.7,2.0 ],\n",
    "                [ 6.3,2.7,4.9,1.8 ], \n",
    "                [ 7.4,2.8,6.1,1.9 ],\n",
    "                [ 7.9,3.8,6.4,2.0 ],\n",
    "                [ 6.4,2.8,5.6,2.2 ],\n",
    "                [ 5.0,3.4,1.6,0.4 ],\n",
    "                [ 5.2,3.5,1.5,0.2 ],\n",
    "                [ 5.2,3.4,1.4,0.2 ],\n",
    "                [ 4.7,3.2,1.6,0.2 ],\n",
    "                [ 6.3,2.8,5.1,1.5 ],\n",
    "                [ 6.1,2.6,5.6,1.4 ],\n",
    "                [ 7.7,3.0,6.1,2.3 ],\n",
    "                [ 6.3,3.4,5.6,2.4 ],\n",
    "                [ 6.4,3.1,5.5,1.8 ],\n",
    "                [ 6.0,3.0,4.8,1.8 ],\n",
    "                [ 5.8,2.7,5.1,1.9 ],\n",
    "                [ 6.3,2.5,5.0,1.9 ],\n",
    "                [ 6.5,3.0,5.2,2.0 ],\n",
    "                [ 4.4,3.2,1.3,0.2 ],\n",
    "                [ 5.0,3.5,1.6,0.6 ],\n",
    "                [ 5.1,3.8,1.9,0.4 ],\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_Bob_res = np.array([[1], [1],[1], [1], [0], [0], [0], [1], [1], [1], [1], [0], [0], [0], [0], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = np.array([\n",
    "                    [6.2, 3.4, 5.4, 2.3],\n",
    "                    [5.9, 3.0, 5.1, 1.8],\n",
    "                    [5.4, 3.9, 1.3, 0.4],\n",
    "                    [6.8, 3.2, 5.9, 2.3],\n",
    "                    [6.7, 3.3, 5.7, 2.5],\n",
    "                    [6.7, 3.0, 5.2, 2.3],\n",
    "                    [5.1, 3.5, 1.4, 0.3],\n",
    "                    [4.8, 3.1, 1.6, 0.2],\n",
    "                    [5.4, 3.4, 1.5, 0.4],\n",
    "                    [5.7, 3.8, 1.7, 0.3],\n",
    "                    [7.3, 2.9, 6.3, 1.8],\n",
    "                    [6.7, 2.5, 5.8, 1.8],\n",
    "                    [4.9, 3.1, 1.5, 0.1],\n",
    "                    [4.4, 3.0, 1.3, 0.2],\n",
    "                    [5.1, 3.4, 1.5, 0.2],\n",
    "                    [5.0, 3.5, 1.3, 0.3],\n",
    "                    [7.2, 3.6, 6.1, 2.5],\n",
    "                    [6.5, 3.2, 5.1, 2.0],\n",
    "                    [5.1, 3.3, 1.7, 0.5],\n",
    "                    [4.8, 3.4, 1.9, 0.2],\n",
    "                    [5.0, 3.3, 1.4, 0.2],\n",
    "                    [6.3, 3.3, 6.0, 2.5],\n",
    "                    [7.2, 3.2, 6.0, 1.8],\n",
    "                    [6.2, 2.8, 4.8, 1.8],\n",
    "                    [6.1, 3.0, 4.9, 1.8],\n",
    "                    [6.4, 2.8, 5.6, 2.1],\n",
    "                    [7.2, 3.0, 5.8, 1.6],\n",
    "                    [5.8, 2.7, 5.1, 1.9],\n",
    "                    [5.0, 3.0, 1.6, 0.2],\n",
    "                    [4.9, 3.1, 1.5, 0.1]]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_res = np.array([[0],[0],[1],[0],[1],[0],[1],[1],[1],[1],[0],[0],[1],[1],[1],[1],[0],[0],[1],[1],[1],[0],[0],[0],[0],[0],[0],[0],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_atan(x):\n",
    "    result = np.arctan(x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_slope(x):\n",
    "    X = x*x\n",
    "    resultant = (1/(1+X))\n",
    "    return resultant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Alice:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 50000  # Setting training iterations\n",
    "        self.lr = 0.001  # Setting learning rate\n",
    "        self.inputlayer_neurons = data_Alice.shape[1]  # number of features in data set\n",
    "        self.hiddenlayer_neurons = 5 # number of hidden layers neurons\n",
    "        self.output_neurons = 1  # number of neurons at output layer\n",
    "        self.wh = np.random.uniform(size=(self.inputlayer_neurons, self.hiddenlayer_neurons))\n",
    "        self.bh = np.random.uniform(size=(1, self.hiddenlayer_neurons))\n",
    "        self.wout = np.random.uniform(size=(self.hiddenlayer_neurons, self.output_neurons))\n",
    "        self.bout = np.random.uniform(size=(1, self.output_neurons))\n",
    "        self.generate_keypair()\n",
    "        # print(\"Currently in Alice Training\")\n",
    "        # print(\"Shape of wh = \", self.wh.shape)\n",
    "        # print(\"Shape of bh = \", self.bh.shape)\n",
    "        # print(\"Shape of wout = \", self.wout.shape)\n",
    "        # print(\"Shape of bout= \", self.bout.shape)\n",
    "\n",
    "\n",
    "    def training(self,data=data_Alice):\n",
    "        for i in range(self.epoch):\n",
    "    \n",
    "            # Forward Propogation\n",
    "            hidden_layer_input1 = np.dot(data, self.wh)\n",
    "            hidden_layer_input = hidden_layer_input1 + self.bh\n",
    "            hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "            output_layer_input1 = np.dot(hiddenlayer_activations, self.wout)\n",
    "            output_layer_input = output_layer_input1 + self.bout\n",
    "            output = sigmoid(output_layer_input)\n",
    "\n",
    "            # Backpropagation\n",
    "            E = data_Alice_res-output\n",
    "            slope_output_layer = derivatives_sigmoid(output)\n",
    "            slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "            d_output = E * slope_output_layer\n",
    "            Error_at_hidden_layer = d_output.dot(self.wout.T)\n",
    "            d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "            self.wout += hiddenlayer_activations.T.dot(d_output) * self.lr\n",
    "            self.bout += np.sum(d_output, axis=0, keepdims=True) * self.lr\n",
    "            self.wh += data_Alice.T.dot(d_hiddenlayer) * self.lr\n",
    "            self.bh += np.sum(d_hiddenlayer, axis=0, keepdims=True) * self.lr\n",
    "        \n",
    "\n",
    "    def decrypt(self,x):\n",
    "        return self.private_key.decrypt(x)\n",
    "\n",
    "    def generate_keypair(self , n_length = 512):\n",
    "        self.public_key,self.private_key = paillier.generate_paillier_keypair(n_length=n_length)\n",
    "\n",
    "    def encrypt_hyperparams(self):\n",
    "        encrypt = self.public_key.encrypt(1,precision=10)\n",
    "        encry_wh = np.dot(encrypt,self.wh)\n",
    "        encry_bh = np.dot(encrypt,self.bh)\n",
    "        encry_wout = np.dot(encrypt,self.wout)\n",
    "        encry_bout = np.dot(encrypt,self.bout)\n",
    "        return encry_wh,encry_bh,encry_wout,encry_bout\n",
    "\n",
    "    def iter_function(arr,i):\n",
    "            return arr[0][i]\n",
    "                \n",
    "    def Bobs_training(self,encrypted_z,Enc_num1,Enc_num2,Enc_num3,Enc_num4,encrypted_target):\n",
    "        l_rate = (self.lr)\n",
    "        h =  1e-6 \n",
    "        for i in range(1,2):\n",
    "            wh = self.wh\n",
    "            bh = self.bh\n",
    "            wout = self.wout\n",
    "            bout = self.bout\n",
    "            # print(\"Currently in Bob Training\")\n",
    "            # print(\"Shape of wh = \", wh.shape)\n",
    "            # print(\"Shape of bh = \", bh.shape)\n",
    "            # print(\"Shape of wout = \", wout.shape)\n",
    "            # print(\"Shape of bout = \", bout.shape)\n",
    "            \n",
    "            z = np.ndarray(shape=(1,self.hiddenlayer_neurons))\n",
    "            for i in range(encrypted_z.shape[0]):\n",
    "                for j in range(encrypted_z.shape[1]):\n",
    "                    z[i][j]=(self.decrypt(encrypted_z[i][j]))\n",
    "            \n",
    "\n",
    "            num1 = np.ndarray(shape=(1,self.hiddenlayer_neurons))\n",
    "            for i in range(Enc_num1.shape[0]):\n",
    "                for j in range(Enc_num1.shape[1]):\n",
    "                    num1[i][j]=(self.decrypt(Enc_num1[i][j]))\n",
    "\n",
    "            num2 = np.ndarray(shape=(1,self.hiddenlayer_neurons))\n",
    "            for i in range(Enc_num2.shape[0]):\n",
    "                for j in range(Enc_num2.shape[1]):\n",
    "                    num2[i][j]=(self.decrypt(Enc_num2[i][j]))\n",
    "\n",
    "            num3 = np.ndarray(shape=(1,self.hiddenlayer_neurons))\n",
    "            for i in range(Enc_num3.shape[0]):\n",
    "                for j in range(Enc_num3.shape[1]):\n",
    "                    num3[i][j]=(self.decrypt(Enc_num3[i][j]))\n",
    "\n",
    "            num4 = np.ndarray(shape=(1,self.hiddenlayer_neurons))\n",
    "            for i in range(Enc_num4.shape[0]):\n",
    "                for j in range(Enc_num4.shape[1]):\n",
    "                    num4[i][j]=(self.decrypt(Enc_num4[i][j]))\n",
    "\n",
    "            encrypted_target = encrypted_target[0]\n",
    "            target = self.decrypt(encrypted_target)\n",
    "\n",
    "            hiddenlayer_activations = sigmoid(z)\n",
    "            output_layer_input1 = np.dot(hiddenlayer_activations, self.wout)\n",
    "            output_layer_input = output_layer_input1 + self.bout\n",
    "            output = sigmoid(output_layer_input)\n",
    "\n",
    "            dz_dwh=np.zeros(shape=(1,self.inputlayer_neurons))\n",
    "            # print(dz_dwh[0])\n",
    "            for j in range(z.shape[1]): dz_dwh[0][0] +=(num1[0][j] - z[0][j]) / (h)\n",
    "            for j in range(z.shape[1]): dz_dwh[0][1] +=(num2[0][j] - z[0][j]) / (h)\n",
    "            for j in range(z.shape[1]): dz_dwh[0][2] +=(num3[0][j] - z[0][j]) / (h)\n",
    "            for j in range(z.shape[1]): dz_dwh[0][3] +=(num4[0][j] - z[0][j]) / (h)\n",
    "\n",
    "            E = target-output\n",
    "            slope_output_layer = derivatives_sigmoid(output)\n",
    "            slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "            d_output = E * slope_output_layer\n",
    "            Error_at_hidden_layer = d_output.dot(self.wout.T)\n",
    "            d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "            self.wout += hiddenlayer_activations.T.dot(d_output) * self.lr\n",
    "            self.bout += np.sum(d_output, axis=0, keepdims=True) * self.lr\n",
    "            self.wh += dz_dwh.T.dot(d_hiddenlayer) * self.lr\n",
    "            self.bh += np.sum(d_hiddenlayer, axis=0, keepdims=True) * self.lr\n",
    "\n",
    "            self.wh = wh\n",
    "            self.bh = bh\n",
    "            self.wout = wout\n",
    "            self.bout = bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Bob:\n",
    "    \n",
    "    def __init__(self,Alices_public_key, encrypted_wh , encrypted_bh,encrypted_wout,encrypted_bout):\n",
    "        self.public_key = Alices_public_key\n",
    "        self.encrypted_wh = encrypted_wh\n",
    "        self.encrypted_bh = encrypted_bh\n",
    "        self.encrypted_wout = encrypted_wout         \n",
    "        self.encrypted_bout = encrypted_bout        \n",
    "\n",
    "    def z_calc(self,data=data_Bob):\n",
    "        wh = self.encrypted_wh\n",
    "        bh = self.encrypted_bh\n",
    "        wout = self.encrypted_wout\n",
    "        bout = self.encrypted_bout\n",
    "        h =  1e-6 \n",
    "        random_index = np.random.randint(len(data))\n",
    "        point = data[random_index]\n",
    "    \n",
    "        hidden_layer_input1 = np.dot(point, wh)\n",
    "        hidden_layer_input=hidden_layer_input1 + bh\n",
    "        z = hidden_layer_input\n",
    "\n",
    "        hidden_layer_input1 = point[0]*(wh[0]+h)+point[1]*wh[1]+point[2]*wh[2]+point[3]*wh[3]\n",
    "        hidden_layer_input=hidden_layer_input1 + bh + random.uniform(0.11,0.36)*h\n",
    "        num1 = hidden_layer_input\n",
    "\n",
    "        hidden_layer_input1 = point[0]*wh[0]+point[1]*(wh[1]+h)+point[2]*wh[2]+point[3]*wh[3]\n",
    "        hidden_layer_input=hidden_layer_input1 + bh + random.uniform(0.11,0.36)*h\n",
    "        num2 = hidden_layer_input  \n",
    "\n",
    "        hidden_layer_input1 = point[0]*wh[0]+point[1]*wh[1]+point[2]*(wh[2]+h)+point[3]*wh[3]\n",
    "        hidden_layer_input=hidden_layer_input1 + bh + random.uniform(0.11,0.36)*h\n",
    "        num3 = hidden_layer_input  \n",
    "\n",
    "        hidden_layer_input1 = point[0]*wh[0]+point[1]*wh[1]+point[2]*wh[2]+point[3]*(wh[3]+h)\n",
    "        hidden_layer_input=hidden_layer_input1 + bh + random.uniform(0.11,0.36)*h\n",
    "        num4 = hidden_layer_input                \n",
    "        \n",
    "        target = data_Bob_res[random_index]\n",
    "        encryp = self.public_key.encrypt(1,precision=7)\n",
    "        encrypted_target = np.dot(encryp,target)\n",
    "        return z , num1 , num2 , num3, num4 ,encrypted_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Training Completed\n",
      "Bob Training Completed\n",
      "--- 50.0660400390625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Alice -> 1) will train her model 2) encrypt hperprams\n",
    "#3) bob gives z_calc 4) Bobs_training\n",
    "a = Alice()\n",
    "a.training()\n",
    "print(\"Alice Training Completed\")\n",
    "\n",
    "for i in range(1,5000):\n",
    "    WH,BH,WOUT,BOUT = a.encrypt_hyperparams()\n",
    "    b=Bob(a.public_key,WH,BH,WOUT,BOUT)\n",
    "    z , num1, num2 , num3,num4 ,et = b.z_calc()\n",
    "    a.Bobs_training( z , num1,num2,num3,num4,et )\n",
    "print(\"Bob Training Completed\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : 0.06930745627678134\n",
      "True\n",
      "pred : 0.07104254513649612\n",
      "True\n",
      "pred : 0.9238494456113818\n",
      "True\n",
      "pred : 0.06817630795160161\n",
      "True\n",
      "pred : 0.06832521442224157\n",
      "False\n",
      "pred : 0.07010049113209621\n",
      "True\n",
      "pred : 0.9219594504960317\n",
      "True\n",
      "pred : 0.9163540896868\n",
      "True\n",
      "pred : 0.9211878183938013\n",
      "True\n",
      "pred : 0.9229031371861485\n",
      "True\n",
      "pred : 0.06820104041065611\n",
      "True\n",
      "pred : 0.0681384421161927\n",
      "True\n",
      "pred : 0.919396404147158\n",
      "True\n",
      "pred : 0.917201944281392\n",
      "True\n",
      "pred : 0.9213450869274015\n",
      "True\n",
      "pred : 0.9222817390937024\n",
      "True\n",
      "pred : 0.06835402411458101\n",
      "True\n",
      "pred : 0.07329616619311524\n",
      "True\n",
      "pred : 0.9150876978676027\n",
      "True\n",
      "pred : 0.9144162768122313\n",
      "True\n",
      "pred : 0.9212457376701363\n",
      "True\n",
      "pred : 0.06757078907802731\n",
      "True\n",
      "pred : 0.06974467405424961\n",
      "True\n",
      "pred : 0.0741743726619846\n",
      "True\n",
      "pred : 0.07397724100901852\n",
      "True\n",
      "pred : 0.06821146485374308\n",
      "True\n",
      "pred : 0.07119363977553082\n",
      "True\n",
      "pred : 0.06921861957834693\n",
      "True\n",
      "pred : 0.9167266877784884\n",
      "True\n",
      "pred : 0.919396404147158\n",
      "True\n",
      "96.66666666666667\n",
      "--- 0.005563259124755859 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "t = 0\n",
    "for i in range(len(data_test)):\n",
    "    point = data_test[i]\n",
    "    # Forward Propogation\n",
    "    hidden_layer_input1 = np.dot(point, a.wh)\n",
    "    hidden_layer_input=hidden_layer_input1 + a.bh\n",
    "    hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "    output_layer_input1=np.dot(hiddenlayer_activations,a.wout)\n",
    "    output_layer_input= output_layer_input1 + a.bout\n",
    "    output = sigmoid(output_layer_input)\n",
    "    output = output[0][0]\n",
    "    print(\"pred : {}\".format(output))\n",
    "    if (round(output) == data_test_res[i]) :\n",
    "        print (\"True\")\n",
    "        t=t+1\n",
    "    else:\n",
    "        print (\"False\")\n",
    "        \n",
    "Accuracy = float(t/30.0)*100   \n",
    "print (Accuracy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
